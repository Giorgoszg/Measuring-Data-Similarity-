{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supermarket customer analysis\n",
    "\n",
    "**Georgios Zygoykis**  \n",
    "**Ioannis Sakkis**  \n",
    "Mining Big Datasets, MSc Business Analytics  \n",
    "Department of Management Science and Technology  \n",
    "Athens University of Economics and Business "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries:\n",
    "import numpy as np  # import numpy\n",
    "import pandas as pd # import pandas\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import and pre-process the dataset with customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing some basic libraries like pandas and numpy to work with our data , we had to import  data of customers that aquire groceries from our supermarket . Using functionalities like shape and head we get some insight of our customer's demographic characteristics ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Persons_in_Household</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Groceries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>male</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>20000</td>\n",
       "      <td>very_good</td>\n",
       "      <td>3</td>\n",
       "      <td>retired</td>\n",
       "      <td>citrus fruit,semi-finished bread,margarine,rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>28000</td>\n",
       "      <td>good</td>\n",
       "      <td>1</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>tropical fruit,yogurt,coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>34000</td>\n",
       "      <td>very_good</td>\n",
       "      <td>1</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>whole milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>male</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>31000</td>\n",
       "      <td>very_good</td>\n",
       "      <td>3</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>pip fruit,yogurt,cream cheese,meat spreads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>female</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>19000</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "      <td>retired</td>\n",
       "      <td>other vegetables,whole milk,condensed milk,lon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_ID Age     Sex Marital_Status  Education Income Customer_Rating  \\\n",
       "0            1  75    male        married    primary  20000       very_good   \n",
       "1            2  61  female         single  secondary  28000            good   \n",
       "2            3  32    male         single  secondary  34000       very_good   \n",
       "3            4  62    male        married    primary  31000       very_good   \n",
       "4            5  66  female        married  secondary  19000            good   \n",
       "\n",
       "   Persons_in_Household   Occupation  \\\n",
       "0                     3      retired   \n",
       "1                     1    housemaid   \n",
       "2                     1  blue-collar   \n",
       "3                     3  blue-collar   \n",
       "4                     3      retired   \n",
       "\n",
       "                                           Groceries  \n",
       "0  citrus fruit,semi-finished bread,margarine,rea...  \n",
       "1                       tropical fruit,yogurt,coffee  \n",
       "2                                         whole milk  \n",
       "3         pip fruit,yogurt,cream cheese,meat spreads  \n",
       "4  other vegetables,whole milk,condensed milk,lon...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc = pd.read_csv('groceries.csv',sep=';')\n",
    "print(groc.shape)\n",
    "groc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data types of our dataframe . We can see that there are some issues , as culomns that should be numeric are not and there should be further investigation about it ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID              int64\n",
       "Age                     object\n",
       "Sex                     object\n",
       "Marital_Status          object\n",
       "Education               object\n",
       "Income                  object\n",
       "Customer_Rating         object\n",
       "Persons_in_Household     int64\n",
       "Occupation              object\n",
       "Groceries               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial thought was to check for missing values (NA's) . Below you can see that it looks like there are 0 NA's . Thus ,we decided to check those columns that have type issues element wised ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID             0\n",
       "Age                     0\n",
       "Sex                     0\n",
       "Marital_Status          0\n",
       "Education               0\n",
       "Income                  0\n",
       "Customer_Rating         0\n",
       "Persons_in_Household    0\n",
       "Occupation              0\n",
       "Groceries               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite having zero NA's we had to check for wrong entries . After using unique function , we saw that there were some entries that were empty space . That space was missing data , so we had to deal with that later on . Below you can see the columns that had that issue , i.e. Age and Income . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['75', '61', '32', '62', '66', '55', '23', '26', '29', '57', '28',\n",
       "       '40', '53', ' ', '68', '33', '79', '54', '51', '60', '69', '47',\n",
       "       '43', '46', '24', '65', '81', '82', '38', '44', '49', '48', '27',\n",
       "       '35', '63', '80', '41', '78', '37', '21', '36', '71', '85', '34',\n",
       "       '30', '50', '83', '64', '74', '70', '25', '73', '58', '76', '42',\n",
       "       '67', '22', '52', '56', '84', '31', '45', '77', '86', '72', '39',\n",
       "       '59'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.Age.unique() # see space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20000', '28000', '34000', '31000', '19000', '35000', '21000',\n",
       "       '30000', '32000', '26000', '14000', '13000', '9000', '25000', ' ',\n",
       "       '16000', '18000', '23000', '39000', '41000', '40000', '10000',\n",
       "       '33000', '8000', '29000', '37000', '36000', '27000', '22000',\n",
       "       '38000', '17000', '42000', '24000', '44000', '48000', '45000',\n",
       "       '51000', '46000', '12000', '54000', '43000', '53000', '15000',\n",
       "       '3000', '47000', '7000', '56000', '50000', '49000', '11000',\n",
       "       '55000', '4000', '6000', '52000', '57000', '5000', '1000', '64000',\n",
       "       '58000', '2000', '61000', '60000', '0', '59000', '67000', '62000',\n",
       "       '63000', '66000'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.Income.unique() # see space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.Persons_in_Household.unique() # ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groc.Groceries.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It high time we had a look on that space issue . Let's print some records that contain NA's for both columns . You can see that we miss that information , so we will impute those missing values with the mean value of the leftovers . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Persons_in_Household</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Groceries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>68</td>\n",
       "      <td>female</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td></td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "      <td>retired</td>\n",
       "      <td>fruit/vegetable juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>male</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td></td>\n",
       "      <td>poor</td>\n",
       "      <td>1</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>sausage,rolls/buns,soda,chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>female</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td></td>\n",
       "      <td>very_good</td>\n",
       "      <td>3</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>fruit/vegetable juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "      <td>male</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td></td>\n",
       "      <td>very_good</td>\n",
       "      <td>1</td>\n",
       "      <td>retired</td>\n",
       "      <td>root vegetables,onions,hard cheese,frozen vege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143</td>\n",
       "      <td>83</td>\n",
       "      <td>female</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td></td>\n",
       "      <td>very_good</td>\n",
       "      <td>1</td>\n",
       "      <td>retired</td>\n",
       "      <td>whole milk,frozen vegetables</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Customer_ID Age     Sex Marital_Status  Education Income Customer_Rating  \\\n",
       "16            17  68  female        married  secondary                   good   \n",
       "27            28  43    male         single   tertiary                   poor   \n",
       "36            37  38  female        married   tertiary              very_good   \n",
       "82            83  73    male         single  secondary              very_good   \n",
       "142          143  83  female         single   tertiary              very_good   \n",
       "\n",
       "     Persons_in_Household     Occupation  \\\n",
       "16                      3        retired   \n",
       "27                      1  self-employed   \n",
       "36                      3     unemployed   \n",
       "82                      1        retired   \n",
       "142                     1        retired   \n",
       "\n",
       "                                             Groceries  \n",
       "16                               fruit/vegetable juice  \n",
       "27                   sausage,rolls/buns,soda,chocolate  \n",
       "36                               fruit/vegetable juice  \n",
       "82   root vegetables,onions,hard cheese,frozen vege...  \n",
       "142                       whole milk,frozen vegetables  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.loc[groc.Income==' '].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Persons_in_Household</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Groceries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>female</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>25000</td>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>butter,sugar,fruit/vegetable juice,newspapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td></td>\n",
       "      <td>female</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>10000</td>\n",
       "      <td>excellent</td>\n",
       "      <td>3</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td></td>\n",
       "      <td>male</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>37000</td>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>other vegetables,whole milk,frozen vegetables,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td></td>\n",
       "      <td>female</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>27000</td>\n",
       "      <td>very_good</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>sausage,whole milk,curd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td></td>\n",
       "      <td>female</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>23000</td>\n",
       "      <td>fair</td>\n",
       "      <td>1</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>soda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Customer_ID Age     Sex Marital_Status  Education Income Customer_Rating  \\\n",
       "15           16      female        married   tertiary  25000            good   \n",
       "26           27      female        married    primary  10000       excellent   \n",
       "60           61        male        married    primary  37000            good   \n",
       "68           69      female         single  secondary  27000       very_good   \n",
       "89           90      female       divorced  secondary  23000            fair   \n",
       "\n",
       "    Persons_in_Household    Occupation  \\\n",
       "15                     4  entrepreneur   \n",
       "26                     3     housemaid   \n",
       "60                     2  entrepreneur   \n",
       "68                     1      services   \n",
       "89                     1     housemaid   \n",
       "\n",
       "                                            Groceries  \n",
       "15      butter,sugar,fruit/vegetable juice,newspapers  \n",
       "26                                             yogurt  \n",
       "60  other vegetables,whole milk,frozen vegetables,...  \n",
       "68                            sausage,whole milk,curd  \n",
       "89                                               soda  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.loc[groc.Age==' '].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kept subsets for of the lefovers , one for records that contain Age and another one for those that contain income values . The porpuse was to turn those columns to numeric in order to calculate the mean values . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groc_b = groc.loc[groc.Age!=' ']\n",
    "groc_c = groc.loc[groc.Income!=' ']\n",
    "#groc_d = groc.loc[groc.Persons_in_Household!=' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean = round(pd.to_numeric(groc_b.Age).mean(),0)\n",
    "inc_mean = round(pd.to_numeric(groc_c.Income).mean(),0)\n",
    "#print(pd.to_numeric(groc.Persons_in_Household.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing those mean values , it was time to impute the missing values with their mean . The fact that culomn type was string , we had to replace the space with mean . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "groc['Income']=groc['Income'].replace([\" \"], inc_mean)\n",
    "groc['Age']=groc['Age'].replace([\" \"], age_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that have fixed the NA's , we have to change data types so as to finish our data preperation process .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID              int64\n",
       "Age                      int64\n",
       "Sex                     object\n",
       "Marital_Status          object\n",
       "Education               object\n",
       "Income                   int64\n",
       "Customer_Rating         object\n",
       "Persons_in_Household     int64\n",
       "Occupation              object\n",
       "Groceries               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc['Income'] = groc['Income'].astype('int64')\n",
    "groc['Age'] = groc['Age'].astype('int64')\n",
    "groc['Sex'] = groc['Sex'].astype('str')\n",
    "groc['Education'] = groc['Education'].astype('str')\n",
    "groc['Customer_Rating'] = groc['Customer_Rating'].astype('str')\n",
    "groc['Occupation'] = groc['Occupation'].astype('str')\n",
    "groc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#groc.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Compute data (dis-)similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At that stage of our assigment , we had to assess the similarity between customers . We want to form the **dissimilarity matrix** \n",
    "for all given attributes.\n",
    "The most difficult part of this process is to compute similarities , or dissimilarities between sets . Before that we have to create a dictionary , containing groceriy purchases for each and every customer ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(groc)):\n",
    "    groc.Groceries[i] = groc.Groceries[i].split(',')\n",
    "   \n",
    "myDict = {}\n",
    "for i in range(len(groc)):\n",
    "    myDict[i]= groc.Groceries[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an efficient method to compute simmilarities between sets . ***Jaccard distance*** , is a measure of how dis-similar two sets are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard distance for croceries \n",
    "#import itertools\n",
    "\n",
    "#define jaccard similarity (size of intersection over size of union)\n",
    "def jaccard_sim(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2))) # why set ?\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the function to compute a similarity matrix of sets , we can compute a dissimilarity matrix too . Below you can see the code that can provide that functionality ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= [[0]*10000 for _ in range(10000)]\n",
    "a=0\n",
    "for i in myDict.keys():\n",
    "    b=0\n",
    "    for j in myDict.keys():\n",
    "        data1[b][a]=1-jaccard_sim(myDict[i],myDict[j])\n",
    "        b=b+1      \n",
    "    a=a+1  \n",
    "dis_jacr=np.tril(data1, 0)  #Convert into lower triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the distance matrix as far as jaccard distance is concerned ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [1.         0.         0.         ... 0.         0.         0.        ]\n",
      " [1.         1.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [1.         1.         1.         ... 0.         0.         0.        ]\n",
      " [0.90909091 0.77777778 1.         ... 1.         0.         0.        ]\n",
      " [1.         1.         1.         ... 0.8        1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(dis_jacr) # fix diangonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next task is to compute dissimilarity matrix for ***nominal*** data . \n",
    "\n",
    "- Firstly , we have to create dictionaries again from columns contain nominal data . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = groc['Sex'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict1 = groc['Occupation'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict2 = groc['Marital_Status'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again using similar code to the one we used to compute the previous distance matrix , we create a function that takes as input a dictionary of nominal data , and composes a dissimilarity matrix ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nominal_dis(data_dict) :\n",
    "    data1= [[0]*10000 for _ in range(10000)]\n",
    "    a=0\n",
    "    for i in data_dict.keys():\n",
    "        b=0\n",
    "        for j in data_dict.keys():\n",
    "            m=0       \n",
    "            if data_dict[i]==data_dict[j]:\n",
    "                m=m\n",
    "            else:\n",
    "                m=1-m\n",
    "            data1[b][a]=m\n",
    "            b=b+1      \n",
    "        a=a+1  \n",
    "    arr=np.tril(data1, 0)  #Convert into lower triangular matrix\n",
    "    #print(arr)\n",
    "    return(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see the output for one distance matrix , concerning dictionaries with Nominal data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " ...\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 1 0 0]\n",
      " [1 1 1 ... 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "dis_Gen = nominal_dis(data_dict)\n",
    "dis_Occ = nominal_dis(data_dict1)\n",
    "dis_Mar = nominal_dis(data_dict2)\n",
    "print(dis_Occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next task is to compute dissimilarity matrix for ***numerical*** data . \n",
    "\n",
    "- We have to create dictionaries again from columns contain numerical data .\n",
    "- Compute a normalizer , to keep values in a scale between [0,1] .\n",
    "- Create a function that composes a distance matrix ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer=max(groc.Age)-min(groc.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Numerical_dis(data_dict):\n",
    "    data1= [[0]*10000 for _ in range(10000)]\n",
    "    a=0\n",
    "    for i in data_dict.keys():\n",
    "        b=0\n",
    "        for j in data_dict.keys():\n",
    "            m=abs(data_dict[i]-data_dict[j])/normalizer\n",
    "            data1[b][a]=m\n",
    "            b=b+1      \n",
    "        a=a+1  \n",
    "    arr=np.tril(data1, 0)  #Convert into lower triangular matrix\n",
    "    return(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following code creates a dissimilarity matrix for every Numerical attribute and prints the output on the console . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.21538462 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.66153846 0.44615385 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.56923077 0.35384615 0.09230769 ... 0.         0.         0.        ]\n",
      " [0.47692308 0.26153846 0.18461538 ... 0.09230769 0.         0.        ]\n",
      " [0.24615385 0.03076923 0.41538462 ... 0.32307692 0.23076923 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "data_dict3 = groc['Age'].to_dict()\n",
    "dis_Age = Numerical_dis(data_dict3)\n",
    "print(dis_Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.4 0.  0.  ... 0.  0.  0. ]\n",
      " [0.4 0.  0.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.2 0.6 0.6 ... 0.  0.  0. ]\n",
      " [0.2 0.6 0.6 ... 0.  0.  0. ]\n",
      " [0.2 0.2 0.2 ... 0.4 0.4 0. ]]\n"
     ]
    }
   ],
   "source": [
    "data_dict6 = groc['Persons_in_Household'].to_dict()\n",
    "normalizer=max(groc.Persons_in_Household)-min(groc.Persons_in_Household)\n",
    "dis_house = Numerical_dis(data_dict6)\n",
    "print(dis_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.11940299 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.20895522 0.08955224 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.3880597  0.26865672 0.17910448 ... 0.         0.         0.        ]\n",
      " [0.04477612 0.07462687 0.1641791  ... 0.34328358 0.         0.        ]\n",
      " [0.01492537 0.10447761 0.19402985 ... 0.37313433 0.02985075 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "data_dict7 = groc['Income'].to_dict()\n",
    "normalizer=max(groc.Income)-min(groc.Income)\n",
    "dis_inc = Numerical_dis(data_dict7)\n",
    "print(dis_inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally , we have to compute the dissimilarity matrix for ***ordinal data*** ,i.e. Customer Rating and Education . \n",
    "- We first check unique values of ordinal dat ,\n",
    "- then , assign numerical values considering the order .\n",
    "- At last , compose distance matrix , normalised . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check unique Rating values . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['very_good', 'good', 'fair', 'excellent', 'poor'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.Customer_Rating.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code we used to assign numerical values to Customer Rating for each customer respectively ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(groc.Customer_Rating)) :\n",
    "    if groc.Customer_Rating[i] == 'excellent' :\n",
    "        groc.Customer_Rating[i] = 5\n",
    "    elif groc.Customer_Rating[i] == 'very_good' :\n",
    "        groc.Customer_Rating[i] = 4 \n",
    "    elif groc.Customer_Rating[i] == 'good' :\n",
    "        groc.Customer_Rating[i] = 3\n",
    "    elif groc.Customer_Rating[i] == 'fair' :\n",
    "        groc.Customer_Rating[i] = 2\n",
    "    else :\n",
    "        groc.Customer_Rating[i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groc.Customer_Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have assigned those numerical values , we can use the function we created before , so as to create the distance matrix . We have calculated again a normalizer , to normalise data distance between [0,1] . You can see the output of the matrix below . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.25 0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.25 0.   ... 0.   0.   0.  ]\n",
      " ...\n",
      " [0.5  0.25 0.5  ... 0.   0.   0.  ]\n",
      " [0.75 0.5  0.75 ... 0.25 0.   0.  ]\n",
      " [0.25 0.   0.25 ... 0.25 0.5  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "data_dict4 = groc['Customer_Rating'].to_dict()\n",
    "normalizer=max(groc.Customer_Rating)-min(groc.Customer_Rating)\n",
    "dis_rating = Numerical_dis(data_dict4)\n",
    "print(dis_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did the same process for education  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['primary', 'secondary', 'tertiary'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groc.Education.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(groc.Education)) :\n",
    "    if groc.Education[i] == 'tertiary' :\n",
    "        groc.Education[i] = 3\n",
    "    elif groc.Education[i] == 'secondary' :\n",
    "        groc.Education[i] = 2\n",
    "    else :\n",
    "        groc.Education[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.5 0.  0.  ... 0.  0.  0. ]\n",
      " [0.5 0.  0.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.  0.5 0.5 ... 0.  0.  0. ]\n",
      " [0.5 0.  0.  ... 0.5 0.  0. ]\n",
      " [1.  0.5 0.5 ... 1.  0.5 0. ]]\n"
     ]
    }
   ],
   "source": [
    "data_dict5 = groc['Education'].to_dict()\n",
    "normalizer=max(groc.Education)-min(groc.Education)\n",
    "dis_educ = Numerical_dis(data_dict5)\n",
    "print(dis_educ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally , we have calculated the distance between clients , computing the average distance for every datatype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.60942084 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.53005485 0.42063401 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.40636561 0.66361143 0.43015691 ... 0.         0.         0.        ]\n",
      " [0.54231001 0.35710479 0.63319939 ... 0.4650657  0.         0.        ]\n",
      " [0.41234214 0.53724965 0.50660161 ... 0.46069014 0.51784666 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "dis_matrix = (dis_Occ + dis_Mar + dis_Gen + dis_Age + dis_rating + dis_educ + dis_house + dis_jacr + dis_inc)/9\n",
    "print(dis_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Nearest Neighbor (NN) search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3rd task is to create a function that takes as input the customer-id and return the list of her/his *10 nearest neighbors* (most similar), along with the corresponding *similarity score*.\n",
    "\n",
    "The function ,takes as input the ID and the number of neighbors we want .Computes a list with the corresponding simmilarities , then creates a dataframe with the asked result .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_search(customer_id,k) :\n",
    "    cust=dis_matrix[customer_id-1,:]+dis_matrix[:,customer_id-1]\n",
    "    A = np.array(cust)\n",
    "    k=k+1\n",
    "    idx = np.argpartition(A, k)\n",
    "    ids=idx[:k]+1\n",
    "    similar=1-A[idx[:k]]\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['Customer_ID'] = ids.tolist()\n",
    "    dataset['Similarity'] = similar.tolist()\n",
    "    dataset = dataset[dataset.Customer_ID != customer_id]\n",
    "    dataset=dataset.sort_values(by=['Similarity'],ascending=False)\n",
    "    return (dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For customers **73, 563, 1603, 2200, 3703, 4263, 5300, 6129, 7800, 8555** we will print their 10 nearest neighbors ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors for customer 73 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "0          1846    0.877514\n",
      "3          1291    0.870188\n",
      "1          1203    0.856563\n",
      "4          5881    0.853451\n",
      "2          1627    0.851008\n",
      "6          3953    0.847538\n",
      "9          6904    0.844608\n",
      "8          5922    0.843969\n",
      "7          8881    0.841191\n",
      "10         3623    0.839827\n",
      "\n",
      "Nearest Neighbors for customer 563 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "0          3634    0.930833\n",
      "1          6168    0.907195\n",
      "2          2839    0.881535\n",
      "4          6196    0.875469\n",
      "5          2766    0.873912\n",
      "8          8108    0.873555\n",
      "6           559    0.870596\n",
      "7          6929    0.868478\n",
      "9          9578    0.866005\n",
      "10         7202    0.865427\n",
      "\n",
      "Nearest Neighbors for customer 1603 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "5          7345    0.868835\n",
      "1          7335    0.860037\n",
      "3           568    0.847255\n",
      "0           109    0.846664\n",
      "2          4814    0.846135\n",
      "4          6751    0.839450\n",
      "7          4628    0.838117\n",
      "8           168    0.836051\n",
      "9          8591    0.832642\n",
      "10         6841    0.832632\n",
      "\n",
      "Nearest Neighbors for customer 2200 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "6           403    0.855879\n",
      "4          7497    0.842767\n",
      "2          8884    0.815936\n",
      "5          6722    0.813382\n",
      "0          5160    0.812923\n",
      "1          3551    0.805262\n",
      "3          5330    0.803897\n",
      "8          4928    0.790955\n",
      "9          6942    0.786905\n",
      "10         2667    0.776119\n",
      "\n",
      "Nearest Neighbors for customer 3703 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "6          9942    0.879782\n",
      "1          1604    0.867521\n",
      "2          4838    0.863707\n",
      "4          3352    0.861641\n",
      "3          1837    0.855770\n",
      "7          3990    0.855017\n",
      "5          7194    0.854956\n",
      "9          7784    0.854803\n",
      "8           374    0.854427\n",
      "10         6793    0.853298\n",
      "\n",
      "Nearest Neighbors for customer 4263 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "4          9536    0.881044\n",
      "7          4990    0.861580\n",
      "0          9051    0.856790\n",
      "5          2195    0.856777\n",
      "3          5829    0.841789\n",
      "2          3822    0.840751\n",
      "1          6183    0.839367\n",
      "8          5427    0.837811\n",
      "9          1896    0.831992\n",
      "10         5755    0.826110\n",
      "\n",
      "Nearest Neighbors for customer 5300 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "1          8497    0.874110\n",
      "0          8982    0.872713\n",
      "2          8711    0.871929\n",
      "3          2110    0.869192\n",
      "5          7457    0.865443\n",
      "6          3533    0.864678\n",
      "7          3470    0.862503\n",
      "8          8068    0.861823\n",
      "9          1999    0.861602\n",
      "10         8905    0.858987\n",
      "\n",
      "Nearest Neighbors for customer 6129 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "2          1082    0.890348\n",
      "4          6303    0.877606\n",
      "7          2029    0.871582\n",
      "1          7563    0.870596\n",
      "6          4933    0.868733\n",
      "3          6387    0.867177\n",
      "5          7870    0.865570\n",
      "8          7557    0.865376\n",
      "9          5680    0.865000\n",
      "10         5301    0.862049\n",
      "\n",
      "Nearest Neighbors for customer 7800 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "0          2126    0.882102\n",
      "3           186    0.878786\n",
      "2          7470    0.855466\n",
      "5          2342    0.838523\n",
      "4          9116    0.834327\n",
      "6           673    0.825090\n",
      "7          8293    0.822579\n",
      "8          1251    0.818102\n",
      "9          8212    0.818102\n",
      "10         1847    0.811111\n",
      "\n",
      "Nearest Neighbors for customer 8555 , along with the corresponding similarities  : \n",
      "    Customer_ID  Similarity\n",
      "1          1486    0.876974\n",
      "2          6092    0.875265\n",
      "7          8732    0.868631\n",
      "8          3012    0.867126\n",
      "6          6823    0.866718\n",
      "5          3320    0.861589\n",
      "3          2691    0.860288\n",
      "4          4406    0.858987\n",
      "9          3894    0.858324\n",
      "10         9336    0.858324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_list=[73, 563, 1603, 2200, 3703, 4263, 5300, 6129, 7800, 8555]\n",
    "for i in cust_list :\n",
    "    print(\"Nearest Neighbors for customer {} , along with the corresponding similarities  : \".format(i))\n",
    "    print(NN_search(i,10))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Customer rating prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the disimillarity matrix, excluding the customer rating metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_matrix_rat_ex = (dis_Occ + dis_Mar + dis_Gen + dis_Age + dis_educ + dis_house + dis_jacr + dis_inc)/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Nearest Neighbors (rating excluded) method, we find the 10 nearest neighbors without taking into consideration teh customers rating metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_search_rat_ex(customer_id,k) :\n",
    "    cust=dis_matrix_rat_ex[customer_id-1,:]+dis_matrix_rat_ex[:,customer_id-1]\n",
    "    A = np.array(cust)\n",
    "    k=k+1\n",
    "    idx = np.argpartition(A, k)\n",
    "    ids=idx[:k]+1\n",
    "    similar=1-A[idx[:k]]\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['Customer_ID'] = ids.tolist()\n",
    "    dataset['Similarity'] = similar.tolist()\n",
    "    dataset = dataset[dataset.Customer_ID != customer_id]\n",
    "    dataset=dataset.sort_values(by=['Similarity'],ascending=False)\n",
    "    return (dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example again with customer 73. You can see there is a difference in the list with the 10 nearest neighbors ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New Nearest Neighbors :\n",
      "    Customer_ID  Similarity\n",
      "2          1627    0.863634\n",
      "5          1846    0.862203\n",
      "3          3953    0.859730\n",
      "0          1291    0.853961\n",
      "1          2502    0.853564\n",
      "6          5484    0.852107\n",
      "7          5502    0.850115\n",
      "9          1292    0.848364\n",
      "8          7467    0.848134\n",
      "10         5162    0.847040\n",
      "\n",
      " Ten Nearest Neighbors before exclusing Rating Metric : \n",
      "\n",
      "    Customer_ID  Similarity\n",
      "0          1846    0.877514\n",
      "3          1291    0.870188\n",
      "1          1203    0.856563\n",
      "4          5881    0.853451\n",
      "2          1627    0.851008\n",
      "6          3953    0.847538\n",
      "9          6904    0.844608\n",
      "8          5922    0.843969\n",
      "7          8881    0.841191\n",
      "10         3623    0.839827\n"
     ]
    }
   ],
   "source": [
    "ten_nn = NN_search_rat_ex(73,10)\n",
    "print(\" New Nearest Neighbors :\")\n",
    "print(ten_nn)\n",
    "print(\"\")\n",
    "print(\" Ten Nearest Neighbors before exclusing Rating Metric : \")\n",
    "print(\"\")\n",
    "print(NN_search(73,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Customer_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1627</td>\n",
       "      <td>0.863634</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1846</td>\n",
       "      <td>0.862203</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3953</td>\n",
       "      <td>0.859730</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1291</td>\n",
       "      <td>0.853961</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2502</td>\n",
       "      <td>0.853564</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5484</td>\n",
       "      <td>0.852107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5502</td>\n",
       "      <td>0.850115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1292</td>\n",
       "      <td>0.848364</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7467</td>\n",
       "      <td>0.848134</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5162</td>\n",
       "      <td>0.847040</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_ID  Similarity Customer_Rating\n",
       "0         1627    0.863634               5\n",
       "1         1846    0.862203               4\n",
       "2         3953    0.859730               3\n",
       "3         1291    0.853961               4\n",
       "4         2502    0.853564               2\n",
       "5         5484    0.852107               1\n",
       "6         5502    0.850115               2\n",
       "7         1292    0.848364               3\n",
       "8         7467    0.848134               3\n",
       "9         5162    0.847040               2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_nn = pd.merge(ten_nn,groc[['Customer_ID','Customer_Rating']],on='Customer_ID',how='left')\n",
    "ten_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we merge the nearest neighbors with our initial dataset in order to find their ratings. Then, in classification using mean as factor to classify customer rating, we simply calculate the mean of all ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_class(dataset):\n",
    "    dataset = pd.merge(dataset,groc[['Customer_ID','Customer_Rating']],on='Customer_ID',how='left')\n",
    "    return(round(dataset.Customer_Rating.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification with weighted average, we use the rank of customer's nearest neighbors , along with their similarity score as weight . So , below there is a function that classifies customers to a rating ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavg_class(dataset):\n",
    "    dataset = pd.merge(dataset,groc[['Customer_ID','Customer_Rating']],on='Customer_ID',how='left')\n",
    "    num= 0\n",
    "    den= 0\n",
    "    for i in range(len(ten_nn)):\n",
    "        num += dataset.Similarity[i] * dataset.Customer_Rating[i]\n",
    "        den += dataset.Similarity[i]    \n",
    "    return(round(num/den))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the real rating in y_true list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = groc.Customer_Rating.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted class, from average method, is stored in in y_avg list ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_avg = []\n",
    "for i in range(0,50):\n",
    "    df = NN_search_rat_ex(i,10)\n",
    "    rating = mean_class(df)\n",
    "    y_avg.append(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted class, from weighted average method, is stored in in y_wavg list ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_wavg = []\n",
    "for i in range(0,50):\n",
    "    df = NN_search_rat_ex(i,10)\n",
    "    rating = wavg_class(df)\n",
    "    y_wavg.append(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataframe with the true ratings and the predicted ratings through average and weighted average methods accoridngly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_avg = pd.DataFrame(y_avg)\n",
    "y_wavg = pd.DataFrame(y_wavg)\n",
    "\n",
    "ratings = pd.concat([y_true, y_avg,y_wavg], axis=1)\n",
    "ratings.columns.values[0] = \"y_true\"\n",
    "ratings.columns.values[1] = \"y_avg\"\n",
    "ratings.columns.values[2] = \"y_wavg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the Customer Ratings , along with their the corresponding encoding .\n",
    "\n",
    "1 - poor  \n",
    "2 - fair  \n",
    "3 - good  \n",
    "4 - very_good  \n",
    "5 - excellent\n",
    "\n",
    "   Thus , below you can see a Dataframe , named `ratings` with the true rating , the average rating prediction prediction and the weighted average prediction respectively ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_avg</th>\n",
       "      <th>y_wavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_true  y_avg  y_wavg\n",
       "0       4      3       3\n",
       "1       3      3       3\n",
       "2       4      4       4\n",
       "3       4      4       4\n",
       "4       3      2       3\n",
       "5       4      3       3\n",
       "6       3      3       3\n",
       "7       3      3       3\n",
       "8       4      3       3\n",
       "9       3      3       3\n",
       "10      4      3       3\n",
       "11      4      3       3\n",
       "12      2      4       4\n",
       "13      2      3       3\n",
       "14      4      3       3\n",
       "15      3      3       3\n",
       "16      3      3       3\n",
       "17      4      3       3\n",
       "18      4      3       3\n",
       "19      2      3       3\n",
       "20      3      2       2\n",
       "21      4      3       3\n",
       "22      3      3       3\n",
       "23      2      3       3\n",
       "24      5      3       3\n",
       "25      3      3       3\n",
       "26      5      3       3\n",
       "27      1      3       3\n",
       "28      3      3       3\n",
       "29      3      3       3\n",
       "30      1      3       3\n",
       "31      5      3       3\n",
       "32      3      3       3\n",
       "33      4      3       3\n",
       "34      3      3       3\n",
       "35      2      3       3\n",
       "36      4      3       3\n",
       "37      2      3       3\n",
       "38      2      3       3\n",
       "39      4      3       3\n",
       "40      3      3       3\n",
       "41      3      3       3\n",
       "42      4      3       3\n",
       "43      3      3       3\n",
       "44      2      3       3\n",
       "45      4      2       3\n",
       "46      3      3       3\n",
       "47      4      3       3\n",
       "48      3      3       3\n",
       "49      2      3       3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the numerators for both cases, in order to find the mean prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Prediction Error with average: 0.76\n",
      "Mean Prediction Error with weighted average: 0.72\n"
     ]
    }
   ],
   "source": [
    "num=0\n",
    "wnum=0\n",
    "for i in range(0,50):\n",
    "    num += abs(ratings.y_true[i]-ratings.y_avg[i])\n",
    "    wnum += abs(ratings.y_true[i]-ratings.y_wavg[i])\n",
    "print('Mean Prediction Error with average:',num/50)\n",
    "print('Mean Prediction Error with weighted average:',wnum/50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that, by using the weighted average method we can achieve a smaller mean prediction error and as a result we can infer that it is a more efficient method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
